{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Allocation quality vs. runtime for various configurations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we evaluate the impact of splitting larger optimization problems into smaller sub-problems on policy runtime and quality of solution for max-min fairness policies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import statements and plotting code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import matplotlib\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import matplotlib.lines as mlines\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "import seaborn as sns\n",
    "from matplotlib import rc\n",
    "import numpy as np\n",
    "sns.set_style('ticks')\n",
    "font = {\n",
    "    'font.family':'Roboto',\n",
    "    'font.size': 12,\n",
    "}\n",
    "sns.set_style(font)\n",
    "paper_rc = {\n",
    "    'lines.linewidth': 3,\n",
    "    'lines.markersize': 10,\n",
    "}\n",
    "sns.set_context(\"paper\", font_scale=2, rc=paper_rc)\n",
    "current_palette = sns.color_palette()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_runtime_vs_metrics(runtimes, metrics,\n",
    "                            metric_label,\n",
    "                            xticks,\n",
    "                            yticks,\n",
    "                            label_locations=None,\n",
    "                            errorbars=False):\n",
    "    plt.figure(figsize=(6.5, 2.5))\n",
    "    ax = plt.subplot2grid((1, 1), (0, 0), colspan=1)\n",
    "    labels = list(runtimes.keys())\n",
    "    for label in labels:\n",
    "        mean_runtimes = []\n",
    "        mean_metrics = []\n",
    "        metric_error_bars = []\n",
    "        runtime_error_bars = []\n",
    "        for runtime, metric in zip(runtimes[label], metrics[label]):\n",
    "            mean_runtimes.append(np.mean(runtime))\n",
    "            mean_metrics.append(np.mean(metric))\n",
    "            runtime_error_bars.append(np.std(runtime))\n",
    "            metric_error_bars.append(np.std(metric))\n",
    "        print(label, mean_runtimes, mean_metrics)\n",
    "        ax.scatter(mean_runtimes, mean_metrics, label=label)\n",
    "        if errorbars:\n",
    "            ax.errorbar(mean_runtimes, mean_metrics, xerr=runtime_error_bars,\n",
    "                        yerr=metric_error_bars)\n",
    "        if label_locations is None:\n",
    "            ax.annotate(label, (mean_runtimes[0], mean_metrics[0]*1.1))\n",
    "        else:\n",
    "            ax.annotate(label, label_locations[label])\n",
    "\n",
    "    ax.set_xscale('log')\n",
    "    xmin, xmax = plt.xlim()\n",
    "    ymin, ymax = plt.ylim()\n",
    "    if yticks is not None:\n",
    "        plt.ylim(0, ymax*1.15)\n",
    "    xmin, xmax = plt.xlim()\n",
    "    ymin, ymax = plt.ylim()\n",
    "\n",
    "    ax.set_ylabel(metric_label)\n",
    "    ax.set_xlabel(\"Runtime (seconds)\")\n",
    "    if yticks is not None:\n",
    "        ax.set_yticks(yticks)\n",
    "    sns.despine()\n",
    "            \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics_vs_num_sub_problems(metrics,\n",
    "                                     metric_label,\n",
    "                                     xticks,\n",
    "                                     yticks):\n",
    "    plt.figure(figsize=(6.5, 2.5))\n",
    "    ax = plt.subplot2grid((1, 1), (0, 0), colspan=1)\n",
    "    labels = list(metrics.keys())\n",
    "    all_num_sub_problems = []\n",
    "    all_metrics = []\n",
    "    for label in labels:\n",
    "        mean_metrics = []\n",
    "        metric_error_bars = []\n",
    "        num_sub_problems = 1\n",
    "        if label.startswith(\"POP-\"):\n",
    "            num_sub_problems = int(label.split(\"POP-\")[1].strip())\n",
    "        for metric in metrics[label]:\n",
    "            mean_metrics.append(np.mean(metric))\n",
    "            metric_error_bars.append(np.std(metric))\n",
    "        all_num_sub_problems.append(num_sub_problems)\n",
    "        all_metrics.append(mean_metrics[-1])\n",
    "    ax.plot(all_num_sub_problems, all_metrics, marker='o')\n",
    "\n",
    "    ax.set_ylabel(metric_label)\n",
    "    ax.set_xlabel(\"Number of sub-problems\")\n",
    "    ax.set_xticks(xticks)\n",
    "    if yticks is not None:\n",
    "        ax.set_yticks(yticks)\n",
    "    sns.despine()\n",
    "            \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot runtime vs. allocation quality and allocation quality vs. number of sub-problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_values(filename):\n",
    "    parsed_values = {}\n",
    "    skip_line = True\n",
    "    with open(filename, 'r') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            line_tokens = line.split('\\t')\n",
    "            \n",
    "            # Skip first line (header).\n",
    "            if skip_line:\n",
    "                skip_line = False\n",
    "                continue\n",
    "\n",
    "            [v100s, p100s, k80s, policy, k, seed, num_jobs_or_lambda,\n",
    "             objective_value, runtime] = line_tokens\n",
    "            system_name = \"POP-%s\" % k\n",
    "            num_jobs_or_lambda = float(num_jobs_or_lambda)\n",
    "            seed = int(seed)\n",
    "            try:\n",
    "                runtime = float(runtime)\n",
    "                objective_value = float(objective_value)\n",
    "            except:\n",
    "                continue\n",
    "            if num_jobs_or_lambda not in parsed_values:\n",
    "                parsed_values[num_jobs_or_lambda] = {}\n",
    "            if system_name not in parsed_values[num_jobs_or_lambda]:\n",
    "                parsed_values[num_jobs_or_lambda][system_name] = []\n",
    "            parsed_values[num_jobs_or_lambda][system_name].append(\n",
    "                (seed, runtime, objective_value))\n",
    "    runtimes = {}\n",
    "    objective_values = {}\n",
    "    for x in parsed_values:\n",
    "        for y in parsed_values[x]:\n",
    "            if y not in runtimes:\n",
    "                runtimes[y] = []\n",
    "                objective_values[y] = []\n",
    "            runtimes[y].append([z[1] for z in parsed_values[x][y]])\n",
    "            objective_values[y].append([z[2] for z in parsed_values[x][y]])\n",
    "    return runtimes, objective_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "policies = [\"max_min_fairness_perf\"]\n",
    "ylabels = [\"Average JCT\\n(hours)\"]\n",
    "all_xticks = [[0.1, 1.0, 10.0]]\n",
    "all_yticks = [[0, 25, 50, 75, 100]]\n",
    "for (policy, ylabel, xticks, yticks) in zip(\n",
    "    policies, ylabels, all_xticks, all_yticks):\n",
    "    runtimes, objective_values = parse_values(\"%s.tsv\" % policy)\n",
    "    plot_runtime_vs_metrics(\n",
    "        runtimes, objective_values,\n",
    "        ylabel,\n",
    "        xticks,\n",
    "        yticks)\n",
    "    plot_metrics_vs_num_sub_problems(\n",
    "        objective_values,\n",
    "        ylabel,\n",
    "        [1, 2, 4, 8],\n",
    "        yticks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
